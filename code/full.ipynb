{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8kP5DjKoFQS7"
      },
      "outputs": [],
      "source": [
        "Link = 'https://github.com/natsunoyuki/blog_posts/blob/main/data_science/Bayesian%20Optimization%20of%20Model%20Hyperparameters.ipynb'\n",
        "db_link = 'https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BASIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "VWCENWUzFQS9"
      },
      "outputs": [],
      "source": [
        "SEED = 1412\n",
        "Test_Ratio = 0.2\n",
        "\n",
        "import os \n",
        "import json \n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Already Got this Data Folder too\n",
            "High on Energy\n"
          ]
        }
      ],
      "source": [
        "Home = os.getcwd()\n",
        "DataFolder = 'Data'\n",
        "DataFolder = os.path.join(Home,DataFolder)\n",
        "\n",
        "MainResultFolder = 'Main_Result'\n",
        "try:\n",
        "    os.mkdir(MainResultFolder)\n",
        "except:\n",
        "    print('Already Got this Data Folder too')\n",
        "MainResultFolder = os.path.join(Home,MainResultFolder)\n",
        "\n",
        "Supplementary_result = 'Supplementary_Result'\n",
        "try:\n",
        "    os.mkdir(Supplementary_result)\n",
        "except:\n",
        "    print('High on Energy')\n",
        "Supplementary_result = os.path.join(Home,Supplementary_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BASIC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Merge_all():\n",
        "    DataBase = [os.path.join(DataFolder,i) for i in os.listdir(DataFolder) if i != 'Train.csv' and i != 'Test.csv']\n",
        "    print(f'Len db -> {len(DataBase)}')\n",
        "    if len(DataBase) == 1:\n",
        "        return\n",
        "    Mydf = pd.read_csv(DataBase[0])\n",
        "\n",
        "    for i in range(1,len(DataBase)):\n",
        "        CurrDF = pd.read_csv(DataBase[i])\n",
        "        Mydf = pd.concat([Mydf,CurrDF])\n",
        "        os.remove(DataBase[i])\n",
        "    Mydf.to_csv(os.path.join(DataFolder,'DataSet.csv'))\n",
        "    os.remove(DataBase[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Len db -> 2\n",
            "['Unnamed: 0', 'class', 'max_ndvi', '20150720_N', '20150602_N', '20150517_N', '20150501_N', '20150415_N', '20150330_N', '20150314_N', '20150226_N', '20150210_N', '20150125_N', '20150109_N', '20141117_N', '20141101_N', '20141016_N', '20140930_N', '20140813_N', '20140626_N', '20140610_N', '20140525_N', '20140509_N', '20140423_N', '20140407_N', '20140322_N', '20140218_N', '20140202_N', '20140117_N', '20140101_N']\n",
            "['class', 'max_ndvi', '20150720_N', '20150602_N', '20150517_N', '20150501_N', '20150415_N', '20150330_N', '20150314_N', '20150226_N', '20150210_N', '20150125_N', '20150109_N', '20141117_N', '20141101_N', '20141016_N', '20140930_N', '20140813_N', '20140626_N', '20140610_N', '20140525_N', '20140509_N', '20140423_N', '20140407_N', '20140322_N', '20140218_N', '20140202_N', '20140117_N', '20140101_N']\n"
          ]
        }
      ],
      "source": [
        "#Crowdsourced Mapping\n",
        "#Link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00400/Crowdsourced%20Mapping.zip' \n",
        "Merge_all()\n",
        "#For this only as there is already a 80-20 established split \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DataBase = [os.path.join(DataFolder,i) for i in os.listdir(DataFolder) if i != 'Train.csv' and i != 'Test.csv'][0]\n",
        "\n",
        "df = pd.read_csv(DataBase)\n",
        "\n",
        "df_col = list(df.columns)\n",
        "print(df_col)\n",
        "\n",
        "df = df.dropna()\n",
        "df = df.drop(columns=[i for i in df_col if i.startswith('Unnamed')])\n",
        "\n",
        "df_col = list(df.columns)\n",
        "print(df_col)\n",
        "\n",
        "y_col = 'class'\n",
        "x_col = [i for i in df_col if i != y_col]\n",
        "\n",
        "y = df[y_col]\n",
        "X = df[x_col]\n",
        "\n",
        "#Encoding Y \n",
        "set_y = list(set(y))\n",
        "dict_y = dict()\n",
        "for i in range(len(set_y)):\n",
        "    dict_y[set_y[i]] = i\n",
        "y = [dict_y[i] for i in df[y_col]]\n",
        "\n",
        "with open(os.path.join(Supplementary_result,'Y_encoding.json'),'w') as temp_dict:\n",
        "    json.dump(dict_y,fp=temp_dict)\n",
        "    \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = Test_Ratio, random_state = SEED)\n",
        "\n",
        "Train = pd.DataFrame(X_train)\n",
        "Train['Answers'] = y_train\n",
        "Test = pd.DataFrame(X_test)\n",
        "Test['Answers'] = y_test\n",
        "\n",
        "Train_Folder = os.path.join(DataFolder,'Train.csv')\n",
        "Test_Folder = os.path.join(DataFolder,'Test.csv')\n",
        "\n",
        "Train.to_csv(Train_Folder)\n",
        "Test.to_csv(Test_Folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"ai4i2020.csv\\n#Link = 'https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset'\\nfrom sklearn.model_selection import train_test_split\\n\\nDataBase = [os.path.join(DataFolder,i) for i in os.listdir(DataFolder) if i != 'Train.csv' and i != 'Test.csv'][0]\\n\\ndf = pd.read_csv(DataBase)\\n\\ndf = df.dropna()\\ndf = df.drop(columns=['UDI','Product ID'])\\n\\ndf_col = list(df.columns)\\nprint(df_col)\\n\\ny_col = 'Type'\\nx_col = [i for i in df_col if i != y_col]\\ny = [1 if i == 'L' else 2 if  i == 'M' else 3 for i in df[y_col]]\\nX = df[x_col]\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = Test_Ratio, random_state = SEED)\\n\\nTrain = pd.DataFrame(X_train)\\nTrain['Answers'] = y_train\\nTest = pd.DataFrame(X_test)\\nTest['Answers'] = y_test\\n\\nTrain_Folder = os.path.join(DataFolder,'Train.csv')\\nTest_Folder = os.path.join(DataFolder,'Test.csv')\\n\\nTrain.to_csv(Train_Folder)\\nTest.to_csv(Test_Folder)\\n\""
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''ai4i2020.csv\n",
        "#Link = 'https://archive.ics.uci.edu/ml/datasets/AI4I+2020+Predictive+Maintenance+Dataset'\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DataBase = [os.path.join(DataFolder,i) for i in os.listdir(DataFolder) if i != 'Train.csv' and i != 'Test.csv'][0]\n",
        "\n",
        "df = pd.read_csv(DataBase)\n",
        "\n",
        "df = df.dropna()\n",
        "df = df.drop(columns=['UDI','Product ID'])\n",
        "\n",
        "df_col = list(df.columns)\n",
        "print(df_col)\n",
        "\n",
        "y_col = 'Type'\n",
        "x_col = [i for i in df_col if i != y_col]\n",
        "y = [1 if i == 'L' else 2 if  i == 'M' else 3 for i in df[y_col]]\n",
        "X = df[x_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = Test_Ratio, random_state = SEED)\n",
        "\n",
        "Train = pd.DataFrame(X_train)\n",
        "Train['Answers'] = y_train\n",
        "Test = pd.DataFrame(X_test)\n",
        "Test['Answers'] = y_test\n",
        "\n",
        "Train_Folder = os.path.join(DataFolder,'Train.csv')\n",
        "Test_Folder = os.path.join(DataFolder,'Test.csv')\n",
        "\n",
        "Train.to_csv(Train_Folder)\n",
        "Test.to_csv(Test_Folder)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Liver\\nfrom sklearn.model_selection import train_test_split\\n\\nDataBase = [os.path.join(DataFolder,i) for i in os.listdir(DataFolder) if i != 'Train.csv' and i != 'Test.csv'][0]\\n\\ndf = pd.read_csv(DataBase)\\n\\ndf_col = list(df.columns)\\n#print(df_col)\\ndf = df.dropna()\\n\\ndf['Gender'] = [1 if i == 'Male' else 2 for i in df['Gender']]\\ny_col = 'Dataset'\\nx_col = [i for i in df_col if i != y_col]\\ny = df[y_col]\\nX = df[x_col]\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = Test_Ratio, random_state = SEED)\\n\\nTrain = pd.DataFrame(X_train)\\nTrain['Answers'] = y_train\\nTest = pd.DataFrame(X_test)\\nTest['Answers'] = y_test\\n\\nTrain_Folder = os.path.join(DataFolder,'Train.csv')\\nTest_Folder = os.path.join(DataFolder,'Test.csv')\\n\\nTrain.to_csv(Train_Folder)\\nTest.to_csv(Test_Folder)\\n\\n\""
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''Liver\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DataBase = [os.path.join(DataFolder,i) for i in os.listdir(DataFolder) if i != 'Train.csv' and i != 'Test.csv'][0]\n",
        "\n",
        "df = pd.read_csv(DataBase)\n",
        "\n",
        "df_col = list(df.columns)\n",
        "#print(df_col)\n",
        "df = df.dropna()\n",
        "\n",
        "df['Gender'] = [1 if i == 'Male' else 2 for i in df['Gender']]\n",
        "y_col = 'Dataset'\n",
        "x_col = [i for i in df_col if i != y_col]\n",
        "y = df[y_col]\n",
        "X = df[x_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = Test_Ratio, random_state = SEED)\n",
        "\n",
        "Train = pd.DataFrame(X_train)\n",
        "Train['Answers'] = y_train\n",
        "Test = pd.DataFrame(X_test)\n",
        "Test['Answers'] = y_test\n",
        "\n",
        "Train_Folder = os.path.join(DataFolder,'Train.csv')\n",
        "Test_Folder = os.path.join(DataFolder,'Test.csv')\n",
        "\n",
        "Train.to_csv(Train_Folder)\n",
        "Test.to_csv(Test_Folder)\n",
        "\n",
        "''' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train_File = os.path.join(DataFolder,'Train.csv')\n",
        "Test_File = os.path.join(DataFolder,'Test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "sEYaYCfwWncq"
      },
      "outputs": [],
      "source": [
        "Train = pd.read_csv(Train_File)\n",
        "Test = pd.read_csv(Test_File)\n",
        "col_lst = list(Test.columns)\n",
        "col_lst.remove('Answers')\n",
        "col_lst = [i for i in col_lst if not i.startswith('Unnamed')]\n",
        "X_train = Train[col_lst]\n",
        "X_test = Test[col_lst]\n",
        "y_train = Train['Answers']\n",
        "y_test = Test['Answers']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nclf = RandomForestClassifier()\\nclf.fit(X_train,y_train)\\nans = clf.score(X_test,y_test)\\nans\\n'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train,y_train)\n",
        "ans = clf.score(X_test,y_test)\n",
        "ans\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjwzmHJ9ei3T",
        "outputId": "0cf8e82c-2687-4ca7-a31b-666c75ebb661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2169, 8676)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Test),len(Train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "hQa-0Ofoe8yQ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np \n",
        "import niapy\n",
        "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbhs_5Bhe8yS"
      },
      "source": [
        "CUCKOO SEARCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "RPrU3DTMe8yS"
      },
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic import CuckooSearch\n",
        "\n",
        "CucKoo_pbounds = {'population_size':(10,100),'pa':(0.1,1.0) ,'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "def mdl_Cuckoo(population_size,pa,n_estimator,criterion,max_feature):\n",
        "    \n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "    \n",
        "    Para_lst = [population_size,pa,n_estimator,criterion,max_feature]\n",
        "\n",
        "    Algo = CuckooSearch()\n",
        "    Algo.set_parameters(population_size=population_size,pa=pa,seed=SEED)\n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),\n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1\n",
        "    )\n",
        "    return nia_mdl, Para_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjwskMKUe8yT"
      },
      "source": [
        "CUCKOO SEARCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKpXd9zWe8yT"
      },
      "source": [
        "FIRE FLY "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "th9hn7Yge8yU"
      },
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic import FireflyAlgorithm\n",
        "\n",
        "FireFly_pbounds = {'population_size':(10,100),'alpha':(0.1,1.0),'beta0':(0.01,100),'gamma':(0.1,1.0),'theta':(0.1,1.0),'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "def mdl_Firefly(population_size,alpha,beta0,gamma,theta,n_estimator,criterion,max_feature):\n",
        "    \n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "\n",
        "    Para_lst = [population_size,alpha,beta0,gamma,theta,n_estimator,criterion,max_feature]\n",
        "\n",
        "\n",
        "    Algo = FireflyAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,alpha=alpha,beta0=beta0,gamma=gamma,theta=theta,seed=SEED)\n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1\n",
        "    )\n",
        "    return nia_mdl, Para_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr6i5YwNe8yU"
      },
      "source": [
        "FIRE FLY "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC4cSoSpe8yU"
      },
      "source": [
        "BAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "FHruFa4Ae8yV"
      },
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic import BatAlgorithm\n",
        "\n",
        "BAT_pbounds = {'population_size':(10,100),'loudness':(0.1,1.0),'pulse_rate':(0.1,1.0),'gamma':(0.1,1.0),'alpha':(0.1,1.0),'min_frequency':(0,10),'max_frequency':(10,100),'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "def mdl_Bat(population_size,loudness,pulse_rate,gamma,alpha,min_frequency,max_frequency,n_estimator,criterion,max_feature):\n",
        "    \n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "\n",
        "    Para_lst = [population_size,loudness,pulse_rate,gamma,alpha,min_frequency,max_frequency,n_estimator,criterion,max_feature]\n",
        "\n",
        "    Algo = BatAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,loudness=loudness,pulse_rate=pulse_rate,alpha=alpha,gamma=gamma,min_frequency=min_frequency,max_frequency=max_frequency,seed=SEED)\n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1\n",
        "    )\n",
        "    return nia_mdl, Para_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1x7e8ioe8yW"
      },
      "source": [
        "BAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwQ5o3AJe8yW"
      },
      "source": [
        "SELF ADAPTIVE BAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_NXOmcAYe8yX"
      },
      "outputs": [],
      "source": [
        "from niapy.algorithms.modified import AdaptiveBatAlgorithm\n",
        "\n",
        "SABA_pbounds = {'population_size':(10,100),'loudness':(0.1,1.0),'pulse_rate':(0.1,1.0),'epsilon':(0,0.1),'alpha':(0.1,1.0),'min_frequency':(0,10),'max_frequency':(10,100),'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "def mdl_SBA(population_size,loudness,pulse_rate,epsilon,alpha,min_frequency,max_frequency,n_estimator,criterion,max_feature):\n",
        "    \n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "\n",
        "    Para_lst = [population_size,loudness,pulse_rate,epsilon,alpha,min_frequency,max_frequency,n_estimator,criterion,max_feature]\n",
        "\n",
        "    Algo = AdaptiveBatAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,loudness=loudness,pulse_rate=pulse_rate,alpha=alpha,epsilon=epsilon,min_frequency=min_frequency,max_frequency=max_frequency,seed=SEED)\n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1\n",
        "    )\n",
        "    return nia_mdl, Para_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9EvQl5Ce8yX"
      },
      "source": [
        "SELF ADAPTIVE BAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdK4U0Z3e8yY"
      },
      "source": [
        "PARTICLE SWARM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "F2_0l7Kme8yY"
      },
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic import ParticleSwarmAlgorithm\n",
        "\n",
        "PSA_pbounds = {'population_size':(10,100),'c1':(0,4),'c2':(0,4),'w':(0,1),'min_velocity':(-10,0),'max_velocity':(0,10),'repair':(0,5),'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "def mdl_PSA(population_size,c1,c2,w,min_velocity,max_velocity,repair,n_estimator,criterion,max_feature):\n",
        "\n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "    #limit, limit_inverse, wang, rand, reflect\n",
        "    repair_name = ''\n",
        "    if repair < 1.0:\n",
        "        repair = niapy.util.repair.limit\n",
        "        repair_name = 'limit'\n",
        "    elif repair < 2.0:\n",
        "        repair = niapy.util.repair.limit_inverse\n",
        "        repair_name = 'limit_inverse'\n",
        "    elif repair < 3.0:\n",
        "        repair = niapy.util.repair.wang\n",
        "        repair_name = 'wang'\n",
        "    elif repair < 4.0:\n",
        "        repair = niapy.util.repair.rand\n",
        "        repair_name = 'rand'\n",
        "    else:\n",
        "        repair = niapy.util.repair.reflect\n",
        "        repair_name = 'reflect'\n",
        "\n",
        "    Para_lst = [population_size,c1,c2,w,min_velocity,max_velocity,repair_name,n_estimator,criterion,max_feature]\n",
        "\n",
        "    Algo = ParticleSwarmAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,c1=c1,c2=c2,w=w,min_velocity=min_velocity,max_velocity=max_velocity,repair=repair,seed=SEED) \n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1,\n",
        "    )\n",
        "    return nia_mdl, Para_lst\n",
        "\n",
        "Link = 'https://www.researchgate.net/profile/Mohamed_Mourad_Lafifi/post/Which-is-the-best-swarm-size-in-PSO/attachment/5b5b6f85b53d2f89289c14e1/AS%3A653084896288769%401532718981208/download/Good+Parameters+for+Particle+Swarm+Optimization.pdf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVoHknq7e8yY"
      },
      "source": [
        "PARTICLE SWARM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8f_g9pPjBJ4"
      },
      "source": [
        "Camel Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "C0T8P9H4jBW3"
      },
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic import CamelAlgorithm\n",
        "\n",
        "camel_bounds = {'population_size':(10,100), 'burden_factor':(0.1,1.0), 'death_rate':(0.1,1.0), 'visibility':(0.1,1.0),'supply_init':(1,1000),'endurance_init':(0,1000), 'min_temperature':(-100,0), 'max_temperature':(1,100),'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "def mdl_camel(population_size,burden_factor,death_rate,visibility,supply_init,endurance_init,min_temperature,max_temperature,n_estimator,criterion,max_feature):\n",
        "\n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "    \n",
        "    Para_lst = [population_size,burden_factor,death_rate,visibility,supply_init,endurance_init,min_temperature,max_temperature,n_estimator,criterion,max_feature]\n",
        "\n",
        "    Algo = CamelAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,burden_factor=burden_factor,death_rate=death_rate,visibility=visibility,supply_init=supply_init,endurance_init=endurance_init,min_temperature=min_temperature,max_temperature=max_temperature,seed=SEED) \n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1,\n",
        "    )\n",
        "    return nia_mdl, Para_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVnO6a5_jBkc"
      },
      "source": [
        "Camel Algorithm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic import GeneticAlgorithm\n",
        "\n",
        "ga_bounds = {'population_size':(10,100), 'tournament_size':(1,10), 'mutation_rate':(0.1,1.0), 'crossover_rate':(0.1,1.0),'selection':(0,2),'crossover':(0,4), 'mutation':(0,3), 'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "def mdl_ga(population_size, tournament_size, mutation_rate, crossover_rate, selection, crossover, mutation, n_estimator, criterion, max_feature):\n",
        "\n",
        "    population_size = int(population_size)\n",
        "    tournament_size = int(tournament_size)\n",
        "    n_estimator = int(n_estimator) \n",
        "\n",
        "    '''\n",
        "    * :func:`niapy.algorithms.basic.tournament_selection`\n",
        "    * :func:`niapy.algorithms.basic.roulette_selection`\n",
        "    '''\n",
        "    selection_name = ''\n",
        "    if selection < 1:\n",
        "        selection_name = 'tournament_selection'\n",
        "        selection = niapy.algorithms.basic.tournament_selection\n",
        "    else:\n",
        "        selection_name = 'roulette_selection'\n",
        "        selection = niapy.algorithms.basic.roulette_selection\n",
        "    '''\n",
        "    * :func:`niapy.algorithms.basic.uniform_crossover`\n",
        "    * :func:`niapy.algorithms.basic.two_point_crossover`\n",
        "    * :func:`niapy.algorithms.basic.multi_point_crossover`\n",
        "    * :func:`niapy.algorithms.basic.crossover_uros`\n",
        "    '''\n",
        "    crossover_name = ''\n",
        "    if crossover < 1:\n",
        "        crossover_name = 'uniform_crossover'\n",
        "        crossover =  niapy.algorithms.basic.uniform_crossover\n",
        "    elif crossover < 2:\n",
        "        crossover_name = 'two_point_crossover'\n",
        "        crossover = niapy.algorithms.basic.two_point_crossover\n",
        "    elif crossover < 3:\n",
        "        crossover_name = 'multi_point_crossover'\n",
        "        crossover = niapy.algorithms.basic.multi_point_crossover\n",
        "    else:\n",
        "        crossover_name = 'crossover_uros'\n",
        "        crossover = niapy.algorithms.basic.crossover_uros\n",
        "    '''\n",
        "    * :func:`niapy.algorithms.basic.uniform_mutation`\n",
        "    * :func:`niapy.algorithms.basic.creep_mutation`\n",
        "    * :func:`niapy.algorithms.basic.mutation_uros`\n",
        "    '''\n",
        "    mutation_name = ''\n",
        "    if mutation < 1:\n",
        "        mutation_name = 'uniform_mutation'\n",
        "        mutation = niapy.algorithms.basic.uniform_mutation\n",
        "    elif mutation < 2:\n",
        "        mutation_name = 'creep_mutation'\n",
        "        mutation = niapy.algorithms.basic.creep_mutation\n",
        "    else:\n",
        "        mutation_name = 'mutation_uros'\n",
        "        mutation = niapy.algorithms.basic.mutation_uros\n",
        "\n",
        "\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "    \n",
        "    Para_lst = [population_size,tournament_size,mutation_rate,crossover_rate,selection_name,crossover_name,mutation_name,n_estimator,criterion,max_feature]\n",
        "\n",
        "    Algo = GeneticAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,tournament_size=tournament_size,mutation_rate=mutation_rate,crossover_rate=crossover_rate,selection=selection,crossover=crossover,mutation=mutation,seed=SEED) \n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1,\n",
        "    )\n",
        "    return nia_mdl, Para_lst"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Genetic Algorithm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Artificial Bee Colony "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic import ArtificialBeeColonyAlgorithm\n",
        "\n",
        "abc_bounds = {'population_size':(10,100),'limit' :(20,100), 'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "def mdl_abc(population_size, limit, n_estimator, criterion, max_feature):\n",
        "\n",
        "    population_size = int(population_size)\n",
        "    limit = int(limit)\n",
        "    n_estimator = int(n_estimator) \n",
        "\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "    \n",
        "    Para_lst = [population_size,limit,n_estimator,criterion,max_feature]\n",
        "\n",
        "    Algo = ArtificialBeeColonyAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,limit=limit,seed=SEED) \n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1,\n",
        "    )\n",
        "    return nia_mdl, Para_lst"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Artificial Bee Colony "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Differential Evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic.de import DifferentialEvolution\n",
        "\n",
        "de_bounds = {'population_size':(10,100), 'differential_weight':(0.1,1.0), 'crossover_probability':(0.1,1.0), 'strategy':(0,10), 'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "'''\n",
        "'cross_rand1', 'cross_rand2', 'cross_best1', 'cross_best2', 'cross_curr2rand1',\n",
        "'cross_curr2best1', 'multi_mutations', 'proportional', 'linear', 'bilinear'\n",
        "'''\n",
        "\n",
        "def mdl_de(population_size, differential_weight, crossover_probability, strategy, n_estimator, criterion, max_feature):\n",
        "\n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator) \n",
        "\n",
        "    strategy_name = ''\n",
        "\n",
        "    if strategy < 1:\n",
        "        strategy = niapy.algorithms.basic.de.cross_rand1\n",
        "        strategy_name = 'cross_rand1'\n",
        "    elif strategy < 2:\n",
        "        strategy = niapy.algorithms.basic.de.cross_rand2\n",
        "        strategy_name = 'cross_rand2'\n",
        "    elif strategy < 3:\n",
        "        strategy = niapy.algorithms.basic.de.cross_best1\n",
        "        strategy_name = 'cross_best1'\n",
        "    elif strategy < 4:\n",
        "        strategy = niapy.algorithms.basic.de.cross_best2\n",
        "        strategy_name = 'cross_best2'\n",
        "    elif strategy < 5:\n",
        "        strategy = niapy.algorithms.basic.de.cross_curr2rand1\n",
        "        strategy_name = 'cross_curr2rand1'\n",
        "    elif strategy < 6:\n",
        "        strategy = niapy.algorithms.basic.de.cross_curr2best1\n",
        "        strategy_name = 'cross_curr2best1'\n",
        "    elif strategy < 7:\n",
        "        strategy = niapy.algorithms.basic.de.multi_mutations\n",
        "        strategy_name = 'multi_mutations'\n",
        "    elif strategy < 8:\n",
        "        strategy = niapy.algorithms.basic.de.proportional\n",
        "        strategy_name = 'proportional'\n",
        "    elif strategy < 9:\n",
        "        strategy = niapy.algorithms.basic.de.linear\n",
        "        strategy_name = 'linear'\n",
        "    elif strategy < 10:\n",
        "        strategy = niapy.algorithms.basic.de.bilinear\n",
        "        strategy_name = 'bilinear'\n",
        "\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "    \n",
        "    Para_lst = [population_size,differential_weight,crossover_probability,strategy_name,n_estimator,criterion,max_feature]\n",
        "\n",
        "    Algo = DifferentialEvolution()\n",
        "    Algo.set_parameters(population_size=population_size,differential_weight=differential_weight,crossover_probability=crossover_probability,strategy=strategy,seed=SEED)\n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1,\n",
        "    )\n",
        "    return nia_mdl, Para_lst"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Differential Evolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYISMKude8yZ"
      },
      "source": [
        "BAYESIAN PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "5hKJv7nizJlS"
      },
      "outputs": [],
      "source": [
        "\n",
        "NIA_Name = {0:'Cuckoo Search',1:'Fire Fly',2:'Bat',3:'Self Adaptive Bat',4:'Particle Swarm', 5:'Camel Algorithm', 6:'Genetic Algorithm', 7: 'Artificial Bee Colony', 8:'Differential Evolution'}\n",
        "\n",
        "NIA_pbounds_lst = {0:CucKoo_pbounds, 1:FireFly_pbounds, 2:BAT_pbounds, 3:SABA_pbounds, 4:PSA_pbounds, 5:camel_bounds, 6:ga_bounds, 7:abc_bounds, 8:de_bounds}\n",
        "\n",
        "mdl_fxn = {0:mdl_Cuckoo,1:mdl_Firefly,2:mdl_Bat,3:mdl_SBA,4:mdl_PSA,5:mdl_camel,6:mdl_ga,7:mdl_abc,8:mdl_de}\n",
        "My_Working_lst = [8,4,6,7,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BAYESIAN PARAMETERS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Z1IZsle8yZ"
      },
      "source": [
        "FUNCTION LIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bayes_opt import BayesianOptimization, UtilityFunction\n",
        "from matplotlib import pyplot as plt \n",
        "import time "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\chand\\\\Desktop\\\\temp_here\\\\Green-Computing\\\\code'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ENERGY FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\chand\\\\Desktop\\\\temp_here\\\\Green-Computing\\\\code\\\\kid.csv'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "energy_file = [ os.path.join(os.getcwd(),x) for x in os.listdir() if x.endswith('.csv')][0]\n",
        "energy_file\n",
        "#always check for latest copy whenever you check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Get_Time_Energy(Start_idx,End_idx):\n",
        "\n",
        "    temp_df = pd.read_csv(energy_file)\n",
        "    temp_df_cols = list(temp_df.columns)\n",
        "\n",
        "    ret_dict = {'Time Taken(s)':int(End_idx-Start_idx), 'Total Power(J)':0.0, 'CPU(J)':0.0, 'Monitor(J)':0.0, 'Disk(J)':0.0, 'Base(J)':0.0}\n",
        "    ret_dict_cols = list(ret_dict.keys())\n",
        "\n",
        "    for curr_idx in range(Start_idx,End_idx):\n",
        "\n",
        "        for i in range(1,len(ret_dict_cols)):\n",
        "            ret_dict[ret_dict_cols[i]] += temp_df[temp_df_cols[i]][curr_idx]\n",
        "    \n",
        "    return ret_dict\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BAYESIAN FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "CagnD0eWe8ya",
        "outputId": "e711c148-352c-433e-c7de-2ba712a415b2"
      },
      "outputs": [],
      "source": [
        "def Optimize_and_plot(bounds,curr_mdl_fxn,Algo_name:str,Iters:int):\n",
        "    os.remove(energy_file)\n",
        "    time.sleep(2)\n",
        "    \n",
        "    print(f'Currently at {Algo_name}')\n",
        "\n",
        "    optimizer = BayesianOptimization(f = None, pbounds = bounds, verbose = 2, random_state = SEED)\n",
        "    utility = UtilityFunction(kind = \"ucb\", kappa = 1.96, xi = 0.01)\n",
        "\n",
        "    #ID refers to Iteration ID, it is of format f'{Algo_name[:3]}0{Iteration_no}'\n",
        "    #^ This is gonna be Primary Key\n",
        "\n",
        "    #All Parameters\n",
        "    Parameter_df = pd.DataFrame()\n",
        "    col_lst = ['ID'] + list(bounds.keys())\n",
        "    for col_name in col_lst:\n",
        "        Parameter_df[col_name] = []\n",
        "\n",
        "    #All results like Accuracy, time taken, Energy, CO2 \n",
        "    Result_df = pd.DataFrame()\n",
        "    col_lst = ['ID', 'Accuracy', 'Time Taken (s)', 'Energy Used (J)', 'Equivalent CO2 Emission (mg)']\n",
        "    for col_name in col_lst:\n",
        "        Result_df[col_name] = []\n",
        "\n",
        "    #Energy Distribution\n",
        "    Energy_df = pd.DataFrame()\n",
        "    col_lst = ['ID', 'Time Taken(s)', 'Total Power(J)', 'CPU(J)', 'Monitor(J)', 'Disk(J)', 'Base(J)']\n",
        "    for col_name in col_lst:\n",
        "        Energy_df[col_name] = []\n",
        "\n",
        "    for i in range(Iters):\n",
        "        Curr_ID = f'{Algo_name[:3].upper()}-{i:>4}'.replace(' ','0')\n",
        "        # Get optimizer to suggest a new parameter value to try.\n",
        "        next_point = optimizer.suggest(utility)  \n",
        "        # Evaluate the output of the black_box_function using the new parameter value.\n",
        "\n",
        "        curr_mdl,Para_lst = curr_mdl_fxn(**next_point)\n",
        "\n",
        "        Start_idx = len(pd.read_csv(energy_file))\n",
        "        curr_mdl.fit(X_train,y_train)\n",
        "        target = curr_mdl.score(X_test,y_test)\n",
        "        End_idx = len(pd.read_csv(energy_file))\n",
        "        target = target*100\n",
        "        #print(Start_idx,End_idx)\n",
        "\n",
        "        Parameter_df.loc[len(Parameter_df)] = [Curr_ID] + Para_lst\n",
        "\n",
        "        Energy_dict = Get_Time_Energy(Start_idx,End_idx)\n",
        "        #{'Time Taken(s)':int(End_idx-Start_idx+1), 'Total Power(J)':0.0, 'CPU(J)':0.0, 'Monitor(J)':0.0, 'Disk(J)':0.0, 'Base(J)':0.0}\n",
        "\n",
        "        Result_df.loc[len(Result_df)] = [Curr_ID, target, Energy_dict['Time Taken(s)'], Energy_dict['Total Power(J)'], (17.0/72.0)*Energy_dict['Total Power(J)']]\n",
        "        #['ID', 'Accuracy', 'Time Taken (s)', 'Energy Used (J)', 'Equivalent CO2 Emission (mg)']\n",
        "        \n",
        "        '''emission \n",
        "        1 kW-hr = 0.85 Kg of CO2 emission \n",
        "        36 e5 - 85 e4 mg\n",
        "        360 - 85\n",
        "        72 J - 17mg CO2 \n",
        "        1 J = (17.0/72.0) mg CO2\n",
        "        ''' \n",
        "\n",
        "        Energy_df.loc[len(Energy_df)] = [Curr_ID] + list(Energy_dict.values())\n",
        "        #['ID', 'Time Taken(s)', 'Total Power(J)', 'CPU(J)', 'Monitor(J)', 'Disk(J)', 'Base(J)']\n",
        "\n",
        "        try:\n",
        "            # Update the optimizer with the evaluation results. This needs to be in try-except\n",
        "            # to prevent repeat errors from occuring.\n",
        "            optimizer.register(params = next_point, target = target)\n",
        "        except:\n",
        "            print('What was that?')\n",
        "            pass\n",
        "\n",
        "    Result_df.to_csv(os.path.join(MainResultFolder,f'{Algo_name}.csv')) \n",
        "    Parameter_df.to_csv(os.path.join(Supplementary_result,f'{Algo_name}_Parameter.csv'))\n",
        "    Energy_df.to_csv(os.path.join(Supplementary_result,f'{Algo_name}_Energy_Distribution.csv'))\n",
        "\n",
        "    plt.plot(range(1, 1+len(optimizer.space.target)), optimizer.space.target, \"-o\")\n",
        "    plt.grid(True)\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.show()\n",
        "    plt.savefig(os.path.join(Supplementary_result,f'{Algo_name}_Iterations.png'))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BAYESIAN FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "9KJEEtHze8ya"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 2] The system cannot find the file specified: 'c:\\\\Users\\\\chand\\\\Desktop\\\\temp_here\\\\Green-Computing\\\\code\\\\kid.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\chand\\Desktop\\temp_here\\Green-Computing\\code\\full.ipynb Cell 58\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/temp_here/Green-Computing/code/full.ipynb#Y103sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m My_Working_lst \u001b[39m=\u001b[39m [\u001b[39m8\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m6\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/temp_here/Green-Computing/code/full.ipynb#Y103sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m My_Working_lst:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/temp_here/Green-Computing/code/full.ipynb#Y103sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     Optimize_and_plot(bounds\u001b[39m=\u001b[39;49mNIA_pbounds_lst[i],curr_mdl_fxn\u001b[39m=\u001b[39;49mmdl_fxn[i],Algo_name\u001b[39m=\u001b[39;49mNIA_Name[i],Iters\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
            "\u001b[1;32mc:\\Users\\chand\\Desktop\\temp_here\\Green-Computing\\code\\full.ipynb Cell 58\u001b[0m in \u001b[0;36mOptimize_and_plot\u001b[1;34m(bounds, curr_mdl_fxn, Algo_name, Iters)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/temp_here/Green-Computing/code/full.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mOptimize_and_plot\u001b[39m(bounds,curr_mdl_fxn,Algo_name:\u001b[39mstr\u001b[39m,Iters:\u001b[39mint\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/temp_here/Green-Computing/code/full.ipynb#Y103sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     os\u001b[39m.\u001b[39;49mremove(energy_file)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/temp_here/Green-Computing/code/full.ipynb#Y103sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/temp_here/Green-Computing/code/full.ipynb#Y103sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCurrently at \u001b[39m\u001b[39m{\u001b[39;00mAlgo_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'c:\\\\Users\\\\chand\\\\Desktop\\\\temp_here\\\\Green-Computing\\\\code\\\\kid.csv'"
          ]
        }
      ],
      "source": [
        "#def Optimize_and_plot(bounds,curr_mdl_fxn,Algo_name:str,Iters:int):\n",
        "My_Working_lst = [8,4,6,7,0]\n",
        "for i in My_Working_lst:\n",
        "    Optimize_and_plot(bounds=NIA_pbounds_lst[i],curr_mdl_fxn=mdl_fxn[i],Algo_name=NIA_Name[i],Iters=50)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BASE CASE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.remove(energy_file)\n",
        "time.sleep(2)\n",
        "curr_mdl = RandomForestClassifier()\n",
        "Start_idx = len(pd.read_csv(energy_file))\n",
        "curr_mdl.fit(X_train,y_train)\n",
        "target = curr_mdl.score(X_test,y_test)\n",
        "End_idx = len(pd.read_csv(energy_file))\n",
        "\n",
        "Energy_dict = Get_Time_Energy(Start_idx,End_idx)\n",
        "#{'Time Taken(s)':int(End_idx-Start_idx+1), 'Total Power(J)':0.0, 'CPU(J)':0.0, 'Monitor(J)':0.0, 'Disk(J)':0.0, 'Base(J)':0.0}\n",
        "\n",
        "Curr_ID = 'BASE-0001'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#All results like Accuracy, time taken, Energy, CO2 \n",
        "Result_df = pd.DataFrame()\n",
        "col_lst = ['ID', 'Accuracy', 'Time Taken (s)', 'Energy Used (J)', 'Equivalent CO2 Emission (mg)']\n",
        "for col_name in col_lst:\n",
        "    Result_df[col_name] = []\n",
        "\n",
        "#Energy Distribution\n",
        "Energy_df = pd.DataFrame()\n",
        "col_lst = ['ID', 'Time Taken(s)', 'Total Power(J)', 'CPU(J)', 'Monitor(J)', 'Disk(J)', 'Base(J)']\n",
        "for col_name in col_lst:\n",
        "    Energy_df[col_name] = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "Result_df.loc[len(Result_df)] = [Curr_ID, target, Energy_dict['Time Taken(s)'], Energy_dict['Total Power(J)'], (17.0/72.0)*Energy_dict['Total Power(J)']]\n",
        "#['ID', 'Accuracy', 'Time Taken (s)', 'Energy Used (J)', 'Equivalent CO2 Emission (mg)']\n",
        "\n",
        "Energy_df.loc[len(Energy_df)] = [Curr_ID] + list(Energy_dict.values())\n",
        "#['ID', 'Time Taken(s)', 'Total Power(J)', 'CPU(J)', 'Monitor(J)', 'Disk(J)', 'Base(J)']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Result_df.to_csv(os.path.join(MainResultFolder,'Base.csv')) \n",
        "Energy_df.to_csv(os.path.join(Supplementary_result,'Base_Energy_Distribution.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BASE CASE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br_NO9vMGbt9"
      },
      "source": [
        "function ClickConnect(){\n",
        "               \n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"#comments > span\").click() \n",
        "}\n",
        "setInterval(ClickConnect,5000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "bcac82fb26a6e7c950421e78519edb87e1a5e005e0aec2fc293e679965bb2493"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
