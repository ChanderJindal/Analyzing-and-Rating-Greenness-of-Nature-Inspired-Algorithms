{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Home = os.getcwd()\n",
    "DataFolder = os.path.join(Home,'Data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyDataFiles = [os.path.join(DataFolder,i) for i in os.listdir(DataFolder) if i.endswith('csv')]\n",
    "lst = []\n",
    "for MyFile in MyDataFiles:\n",
    "    lst.append(pd.read_csv(MyFile))\n",
    "    os.remove(MyFile)\n",
    "df = pd.concat(lst)\n",
    "df_cols = list(df.columns)\n",
    "df = df.drop(columns=[i for i in df_cols if i.startswith('Unnamed:')])\n",
    "df.to_csv(os.path.join(DataFolder,'MyDataSet.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
    "from niapy.algorithms import basic, modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sklearn default\\n    algorithm_obj.set_parameters(\\n        A=0.9, \\n        r=0.1, \\n        Qmin=0.0, \\n        Qmax=2.0)\\n        NP=population_size=50\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NIA_HBAT():\n",
    "    Algo = modified.hba.HybridBatAlgorithm()\n",
    "    return Algo\n",
    "\n",
    "'''NIA default\n",
    "     |  set_parameters(\n",
    "        self, \n",
    "        differential_weight=0.5, \n",
    "        crossover_probability=0.9, \n",
    "        strategy=<function cross_best1 at 0x0000027B012AC790>, \n",
    "        **kwargs)\n",
    "        \n",
    "     |      Set core parameters of HybridBatAlgorithm algorithm.\n",
    "     |      \n",
    "     |      Args:\n",
    "     |          differential_weight (Optional[float]): Differential weight.\n",
    "     |          crossover_probability (Optional[float]): Crossover rate.\n",
    "     |          strategy (Callable): DE Crossover and mutation strategy.\n",
    "''' \n",
    "def sklearn_HBat():\n",
    "    Algo = modified.HybridBatAlgorithm()\n",
    "    #Algo.set_parameters()\n",
    "    return Algo\n",
    "'''sklearn default\n",
    "    algorithm_obj.set_parameters(\n",
    "        A=0.9, \n",
    "        r=0.1, \n",
    "        Qmin=0.0, \n",
    "        Qmax=2.0)\n",
    "        NP=population_size=50\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"default\\nn_estimators=100, \\ncriterion='gini', \\nmax_depth=None, \\nmin_samples_split=2, \\nmin_samples_leaf=1, \\nmin_weight_fraction_leaf=0.0, \\nmax_features='sqrt', \\nmax_leaf_nodes=None, \\nmin_impurity_decrease=0.0, \\nbootstrap=True, \\noob_score=False, \\nn_jobs=None, \\nrandom_state=None, \\nverbose=0, \\nwarm_start=False, \\nclass_weight=None, \\nccp_alpha=0.0, \\nmax_samples=None)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Define_Model():\n",
    "        model = RandomForestClassifier()\n",
    "        param_grid = {}\n",
    "        return model, param_grid\n",
    "#Range\n",
    "'''default\n",
    "n_estimators=100, \n",
    "criterion='gini', \n",
    "max_depth=None, \n",
    "min_samples_split=2, \n",
    "min_samples_leaf=1, \n",
    "min_weight_fraction_leaf=0.0, \n",
    "max_features='sqrt', \n",
    "max_leaf_nodes=None, \n",
    "min_impurity_decrease=0.0, \n",
    "bootstrap=True, \n",
    "oob_score=False, \n",
    "n_jobs=None, \n",
    "random_state=None, \n",
    "verbose=0, \n",
    "warm_start=False, \n",
    "class_weight=None, \n",
    "ccp_alpha=0.0, \n",
    "max_samples=None)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = list(df.columns)\n",
    "y = df[df_cols[-1]]\n",
    "X = df[df_cols[:-1]]\n",
    "model = RandomForestClassifier()\n",
    "param_grid = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting at most 1.0 candidates\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chand\\Desktop\\work_simple\\Green-Computing\\Main\\main2.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/work_simple/Green-Computing/Main/main2.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_hba \u001b[39m=\u001b[39m NatureInspiredSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparam_grid, algorithm\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhsaba\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/work_simple/Green-Computing/Main/main2.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#test_hba = NatureInspiredSearchCV(estimator=RandomForestClassifier(), param_grid={})\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/work_simple/Green-Computing/Main/main2.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_hba\u001b[39m.\u001b[39;49mfit(X,y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/work_simple/Green-Computing/Main/main2.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(test_hba\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn_nature_inspired_algorithms\\model_selection\\nature_inspired_search_cv.py:19\u001b[0m, in \u001b[0;36mNatureInspiredSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_orig \u001b[39m=\u001b[39m check_cv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, y, classifier\u001b[39m=\u001b[39mis_classifier(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator))\n\u001b[0;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_splits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_orig\u001b[39m.\u001b[39mget_n_splits(X, y, groups)\n\u001b[1;32m---> 19\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X, y, groups\u001b[39m=\u001b[39mgroups, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn_nature_inspired_algorithms\\model_selection\\nature_inspired_search_cv.py:47\u001b[0m, in \u001b[0;36mNatureInspiredSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRun \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mruns\u001b[39m}\u001b[39;00m\u001b[39m, Iteration \u001b[39m\u001b[39m{\u001b[39;00miteration\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_n_gen\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mstagnation\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m     38\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m | There were \u001b[39m\u001b[39m{\u001b[39;00mproblem\u001b[39m.\u001b[39mevaluation_count\u001b[39m}\u001b[39;00m\u001b[39m candidates trained until now\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m task \u001b[39m=\u001b[39m StagnationStoppingTask(\n\u001b[0;32m     41\u001b[0m     max_iters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_n_gen,\n\u001b[0;32m     42\u001b[0m     max_stagnating_gen\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_stagnating_gen,\n\u001b[0;32m     43\u001b[0m     problem\u001b[39m=\u001b[39mproblem,\n\u001b[0;32m     44\u001b[0m     iteration_finished_callback\u001b[39m=\u001b[39miteration_finished_callback\n\u001b[0;32m     45\u001b[0m )\n\u001b[1;32m---> 47\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__algorithm\u001b[39m.\u001b[39;49mrun(task\u001b[39m=\u001b[39;49mtask)\n\u001b[0;32m     49\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__algorithm\u001b[39m.\u001b[39mexception:\n\u001b[0;32m     50\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__algorithm\u001b[39m.\u001b[39mexception\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\niapy\\algorithms\\algorithm.py:357\u001b[0m, in \u001b[0;36mAlgorithm.run\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    356\u001b[0m     \u001b[39mif\u001b[39;00m threading\u001b[39m.\u001b[39mcurrent_thread() \u001b[39m==\u001b[39m threading\u001b[39m.\u001b[39mmain_thread() \u001b[39mand\u001b[39;00m multiprocessing\u001b[39m.\u001b[39mcurrent_process()\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMainProcess\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 357\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexception \u001b[39m=\u001b[39m e\n\u001b[0;32m    359\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\niapy\\algorithms\\algorithm.py:353\u001b[0m, in \u001b[0;36mAlgorithm.run\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Start the optimization.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[0;32m    340\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_task(task)\n\u001b[0;32m    354\u001b[0m     \u001b[39mreturn\u001b[39;00m r[\u001b[39m0\u001b[39m], r[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m task\u001b[39m.\u001b[39moptimization_type\u001b[39m.\u001b[39mvalue\n\u001b[0;32m    355\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\niapy\\algorithms\\algorithm.py:333\u001b[0m, in \u001b[0;36mAlgorithm.run_task\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m    331\u001b[0m algo, xb, fxb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miteration_generator(task), \u001b[39mNone\u001b[39;00m, np\u001b[39m.\u001b[39minf\n\u001b[0;32m    332\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m task\u001b[39m.\u001b[39mstopping_condition():\n\u001b[1;32m--> 333\u001b[0m     xb, fxb \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(algo)\n\u001b[0;32m    334\u001b[0m     task\u001b[39m.\u001b[39mnext_iter()\n\u001b[0;32m    335\u001b[0m \u001b[39mreturn\u001b[39;00m xb, fxb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\niapy\\algorithms\\algorithm.py:313\u001b[0m, in \u001b[0;36mAlgorithm.iteration_generator\u001b[1;34m(self, task)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[39myield\u001b[39;00m xb, fxb\n\u001b[0;32m    312\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 313\u001b[0m     pop, fpop, xb, fxb, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_iteration(task, pop, fpop, xb, fxb, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m    314\u001b[0m     \u001b[39myield\u001b[39;00m xb, fxb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\niapy\\algorithms\\modified\\saba.py:386\u001b[0m, in \u001b[0;36mSelfAdaptiveBatAlgorithm.run_iteration\u001b[1;34m(self, task, population, population_fitness, best_x, best_fitness, **params)\u001b[0m\n\u001b[0;32m    384\u001b[0m velocities[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (population[i] \u001b[39m-\u001b[39m best_x) \u001b[39m*\u001b[39m frequency\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom() \u001b[39m>\u001b[39m pulse_rates[i]:\n\u001b[1;32m--> 386\u001b[0m     solution \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocal_search(best\u001b[39m=\u001b[39;49mbest_x, loudness\u001b[39m=\u001b[39;49mloudness[i], task\u001b[39m=\u001b[39;49mtask, i\u001b[39m=\u001b[39;49mi, population\u001b[39m=\u001b[39;49mpopulation)\n\u001b[0;32m    387\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     solution \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mrepair(population[i] \u001b[39m+\u001b[39m velocities[i], rng\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrng)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\niapy\\algorithms\\modified\\hsaba.py:126\u001b[0m, in \u001b[0;36mHybridSelfAdaptiveBatAlgorithm.local_search\u001b[1;34m(self, best, loudness, task, i, population, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlocal_search\u001b[39m(\u001b[39mself\u001b[39m, best, loudness, task, i\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, population\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    113\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Improve the best solution.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \n\u001b[0;32m    115\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m task\u001b[39m.\u001b[39mrepair(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy(population, i, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdifferential_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcrossover_probability, rng\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrng, x_b\u001b[39m=\u001b[39;49mbest), rng\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrng)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\niapy\\algorithms\\basic\\de.py:83\u001b[0m, in \u001b[0;36mcross_best1\u001b[1;34m(pop, ic, f, cr, rng, x_b, **_kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcross_best1\u001b[39m(pop, ic, f, cr, rng, x_b\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs):\n\u001b[0;32m     56\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Mutation strategy with crossover.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m \u001b[39m    Mutation strategy uses two different random individuals from population and global best individual.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m \n\u001b[0;32m     82\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     j \u001b[39m=\u001b[39m rng\u001b[39m.\u001b[39;49mintegers(\u001b[39mlen\u001b[39;49m(pop[ic]))\n\u001b[0;32m     84\u001b[0m     p \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (\u001b[39mlen\u001b[39m(pop) \u001b[39m-\u001b[39m \u001b[39m1.0\u001b[39m) \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m ic \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(pop))] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(pop) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     r \u001b[39m=\u001b[39m rng\u001b[39m.\u001b[39mchoice(\u001b[39mlen\u001b[39m(pop), \u001b[39m2\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(pop) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, p\u001b[39m=\u001b[39mp)\n",
      "File \u001b[1;32m_generator.pyx:543\u001b[0m, in \u001b[0;36mnumpy.random._generator.Generator.integers\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_bounded_integers.pyx:1247\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "test_hba = NatureInspiredSearchCV(estimator=model, param_grid=param_grid, algorithm='hsaba')\n",
    "#test_hba = NatureInspiredSearchCV(estimator=RandomForestClassifier(), param_grid={})\n",
    "test_hba.fit(X,y)\n",
    "print(test_hba.best_score_)\n",
    "#print(Algo.get_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "Pure_model = MLPClassifier()\n",
    "Pure_model.fit(X_train,y_train)\n",
    "Pure_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF -> 90.5% to 91.2%\n",
    "BG -> 90.8% to 91.1%\n",
    "MLP > 90.8% to 91.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fa = NatureInspiredSearchCV(estimator=model, param_grid=param_grid, algorithm='fa')\n",
    "#test_hba = NatureInspiredSearchCV(estimator=RandomForestClassifier(), param_grid={})\n",
    "test_fa.fit(X,y)\n",
    "print(test_fa.best_score_)\n",
    "#print(Algo.get_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_fa.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF -> 90.92\n",
    "BoostedGradient -> 90.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algo = basic.fa.FireflyAlgorithm()\n",
    "test_fa = NatureInspiredSearchCV(estimator=model, param_grid=param_grid, algorithm=Algo)\n",
    "test_fa.fit(X,y)\n",
    "print(test_fa.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF -> 90.92\n",
    "BG -> 90.93\n",
    "MLP -> 90.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NIA_FireFly():\n",
    "    lst = []\n",
    "    for population_size in range(10,101,10):#10\n",
    "        for alpha in np.arange(0.10,0.21,0.01):#10\n",
    "            for beta0 in range(10,101,10):#10\n",
    "                for gamma in np.arange(0.05,1.01,0.05):#19\n",
    "                    for theta in np.arange(0.05,1.01,0.05):#19\n",
    "                        Algo = basic.fa.FireflyAlgorithm()\n",
    "                        Algo.set_parameters(population_size=population_size, \n",
    "                        alpha=alpha, \n",
    "                        beta0=beta0, \n",
    "                        gamma=gamma, \n",
    "                        theta=theta\n",
    "                        )\n",
    "                        lst.append(Algo)\n",
    "    return lst \n",
    "\n",
    "def Sklearn_FireFly():\n",
    "    lst = []\n",
    "    for population_size in range(10,101,10):#10\n",
    "        for alpha in np.arange(0.10,0.21,0.01):#10\n",
    "            for beta0 in range(10,101,10):#10\n",
    "                for gamma in np.arange(0.05,1.01,0.05):#19\n",
    "                    Algo = basic.FireflyAlgorithm()\n",
    "                    Algo.set_parameters(NP=population_size, \n",
    "                    alpha=alpha, \n",
    "                    betamin=beta0, \n",
    "                    gamma=gamma, \n",
    "                    )\n",
    "                    lst.append(Algo)\n",
    "    return lst \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = list(df.columns)\n",
    "y = df[df_cols[-1]]\n",
    "X = df[df_cols[:-1]]\n",
    "model = RandomForestClassifier()\n",
    "param_grid = {}\n",
    "test_hba, name = NatureInspiredSearchCV(estimator=model, param_grid=param_grid, algorithm='hba'), 'Hybrid Bat Algorithm'\n",
    "#test_hba = NatureInspiredSearchCV(estimator=RandomForestClassifier(), param_grid={})\n",
    "test_hba.fit(X,y)\n",
    "print(test_hba.best_score_)\n",
    "print(Algo.get_parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = list(df.columns)\n",
    "y = df[df_cols[-1]]\n",
    "X = df[df_cols[:-1]]\n",
    "model, param_grid = Define_Model()\n",
    "\n",
    "Algo = modified.HybridBatAlgorithm()\n",
    "Algo.set_parameters(A=0.9, r=0.1, Qmin=0.0, Qmax=2.0,NP=50)\n",
    "\n",
    "'''\n",
    "(\n",
    "    differential_weight=0.5,\n",
    "    crossover_probability=0.9\n",
    "    #strategy = basic.de.cross_rand2\n",
    ")\n",
    "''' \n",
    "#del Algo \n",
    "#Algo = basic.de.DifferentialEvolution()\n",
    "#Algo = modified.saba.SelfAdaptiveBatAlgorithm()\n",
    "\n",
    "test_hba = NatureInspiredSearchCV(estimator=model, param_grid=param_grid, algorithm='hba')\n",
    "test_hba.fit(X,y)\n",
    "print(test_hba.best_score_)\n",
    "print(Algo.get_parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, param_grid = Define_Model()\n",
    "Algo_lst = NIA_BAT()\n",
    "print(len(Algo_lst))\n",
    "Best_Score = 0\n",
    "Best_Para = None \n",
    "Bat_Dict = dict()\n",
    "for i in range(len(Algo_lst)):\n",
    "    Curr_Candidate = NatureInspiredSearchCV(estimator=model, param_grid=param_grid, algorithm=Algo_lst[i])\n",
    "    Curr_Candidate.fit(X,y)\n",
    "    Curr_Para = Algo_lst[i].get_parameters()\n",
    "    Curr_Score = Curr_Candidate.best_score_\n",
    "    Bat_Dict[str(Curr_Para)] = Curr_Score\n",
    "    if Curr_Score > Best_Score:\n",
    "        Best_Para = Curr_Para\n",
    "\n",
    "with open('Kids Bat Dict.json','w') as kid:\n",
    "    json.dump(Bat_Dict,kid)\n",
    "\n",
    "print(Best_Score)\n",
    "print(Best_Para)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_try(DataFileName:str,model_val:int):\n",
    "    df = pd.read_csv(DataFileName)\n",
    "    df_cols = list(df.columns)\n",
    "    y = df[df_cols[0]]\n",
    "    X = df[df_cols[1:]]\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,shuffle=False,random_state=1412)\n",
    "    model, NIA_Name = Select_NIS_model(model_val)\n",
    "    model.fit(X,y)\n",
    "    print(f'For {NIA_Name} we get a score of {model.best_score_}.')\n",
    "    #df = pd.DataFrame(model.cv_results_)\n",
    "\n",
    "    #df.to_csv(f\"{NIA_Name}_results.csv\")\n",
    "    return NIA_Name, model.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NIA_Apply(Algo, model, param_grid):\n",
    "        #Fixed\n",
    "    final = NatureInspiredSearchCV(\n",
    "        estimator=model, \n",
    "        algorithm=Algo,\n",
    "        param_grid=param_grid, \n",
    "        max_stagnating_gen=10,\n",
    "        max_n_gen=100\n",
    "        )\n",
    "'''deafult\n",
    "estimator, \n",
    "param_grid, \n",
    "algorithm='hba', \n",
    "population_size=50, \n",
    "max_n_gen=100, \n",
    "runs=3,\n",
    "max_stagnating_gen=20, \n",
    "random_state=None, \n",
    "scoring=None, \n",
    "refit=True, \n",
    "verbose=0,\n",
    "pre_dispatch='2*n_jobs', \n",
    "error_score=np.nan, \n",
    "return_train_score=True\n",
    "             '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Algo_Selector(val:int=1):\n",
    "    if val == 1:\n",
    "        print('Bat')\n",
    "    elif val == 2:\n",
    "        print('Hybrid Bat')\n",
    "    elif val == 3:\n",
    "        print('Self Adapting Hybrid Bat')\n",
    "    else:\n",
    "        print('Fire Fly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((10*6*6*6)+24+24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_try(DataFileName:str,model_val:int):\n",
    "    df = pd.read_csv(DataFileName)\n",
    "    df_cols = list(df.columns)\n",
    "    y = df[df_cols[0]]\n",
    "    X = df[df_cols[1:]]\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,shuffle=False,random_state=1412)\n",
    "    model, NIA_Name = Select_NIS_model(model_val)\n",
    "    model.fit(X,y)\n",
    "    print(f'For {NIA_Name} we get a score of {model.best_score_}.')\n",
    "    #df = pd.DataFrame(model.cv_results_)\n",
    "\n",
    "    #df.to_csv(f\"{NIA_Name}_results.csv\")\n",
    "    return NIA_Name, model.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyDict = dict()\n",
    "My_prev_idx = 0\n",
    "for M_type in range(5):\n",
    "    print(M_type)\n",
    "    for Para in range(50,501,50):\n",
    "        print(Para)\n",
    "        start_time = dt.now()\n",
    "        Name, Score = Model_try(DataFile,M_type,Para)\n",
    "        end_time = dt.now()\n",
    "        #total,cpu,monitor,disk,base, time_taken, end_idx\n",
    "        total,cpu,monitor,disk,base, time_taken, My_prev_idx = Get_Time_Energy(start_time,end_time,prev_idx=My_prev_idx)\n",
    "        TempDict = {'Total Energy (J)' : total, 'Total CPU  Energy (J)' : cpu, 'Total Monitor Energy (J)' : monitor, 'Total Disk Energy (J)' : disk, 'Base Energy (J)' : base, 'Time (Sec)' : time_taken, 'Score' : Score*100, 'n_estimators' : Para}\n",
    "        if Name in MyDict:\n",
    "            MyDict[Name].append(TempDict)\n",
    "        else:\n",
    "            MyDict[Name] = [TempDict]\n",
    "        with open('Kaito Kids Dairy.json','w') as kid:\n",
    "            json.dump(MyDict,kid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specific Value\n",
    "def NIA_Hybrid_Bat():\n",
    "    Algo = modified.HybridBatAlgorithm()\n",
    "    #Vary, for NIA\n",
    "    Algo.set_parameters(\n",
    "        \n",
    "    )\n",
    "    Algo.set_parameters(\n",
    "        population_size = population_size,\n",
    "        loudness = loudness,\n",
    "        pulse_rate = pulse_rate,\n",
    "        alpha = alpha,\n",
    "        gamma = gamma,\n",
    "        min_frequency = min_frequency,\n",
    "        max_frequency = max_frequency\n",
    "    )\n",
    "    return Algo\n",
    "    '''default\n",
    "    differential_weight=0.5, \n",
    "    crossover_probability=0.9, \n",
    "    strategy=<function cross_best1 at 0x000001B81D4F64C0>\n",
    "    '''\n",
    "    #10*6*6*6 +24+24\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcac82fb26a6e7c950421e78519edb87e1a5e005e0aec2fc293e679965bb2493"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
