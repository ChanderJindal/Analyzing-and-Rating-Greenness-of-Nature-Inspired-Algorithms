{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8kP5DjKoFQS7"
      },
      "outputs": [],
      "source": [
        "Link = 'https://github.com/natsunoyuki/blog_posts/blob/main/data_science/Bayesian%20Optimization%20of%20Model%20Hyperparameters.ipynb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq0fwUIDFkId",
        "outputId": "4a6bd01c-86af-4afe-d8da-24a583f445ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting niapy\n",
            "  Downloading niapy-2.0.4-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 15.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.4 in /usr/local/lib/python3.8/dist-packages (from niapy) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.8/dist-packages (from niapy) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from niapy) (1.21.6)\n",
            "Requirement already satisfied: openpyxl>=3.0.3 in /usr/local/lib/python3.8/dist-packages (from niapy) (3.0.10)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.4->niapy) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.4->niapy) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.4->niapy) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.4->niapy) (1.4.4)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.3->niapy) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.2->niapy) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2.4->niapy) (1.15.0)\n",
            "Installing collected packages: niapy\n",
            "Successfully installed niapy-2.0.4\n"
          ]
        }
      ],
      "source": [
        "pip install niapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfp_nrcuFkK1",
        "outputId": "6e865e4e-45ed-4037-efd8-707101cd07f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=af65c582e942dcc274512588bab3e21bf7bf9b30bd06556f1e2424275707ed24\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ],
      "source": [
        "pip install sklearn "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jIy5TXCwFkOY",
        "outputId": "ae3a35e9-5cc6-4543-beb4-252afb23ea8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn-nature-inspired-algorithms\n",
            "  Downloading sklearn_nature_inspired_algorithms-0.9.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: seaborn<1.0.0,>=0.11 in /usr/local/lib/python3.8/dist-packages (from sklearn-nature-inspired-algorithms) (0.11.2)\n",
            "Requirement already satisfied: toml<1.0.0,>=0.10 in /usr/local/lib/python3.8/dist-packages (from sklearn-nature-inspired-algorithms) (0.10.2)\n",
            "Collecting niapy==2.0.2\n",
            "  Downloading niapy-2.0.2-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 23.1 MB/s \n",
            "\u001b[?25hCollecting numpy<2.0.0,>=1.22\n",
            "  Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1 MB 34 kB/s \n",
            "\u001b[?25hCollecting matplotlib<4.0.0,>=3.5\n",
            "  Downloading matplotlib-3.6.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 39.9 MB/s \n",
            "\u001b[?25hCollecting pandas<2.0.0,>=1.4\n",
            "  Downloading pandas-1.5.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2 MB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from sklearn-nature-inspired-algorithms) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.8/dist-packages (from sklearn-nature-inspired-algorithms) (1.7.3)\n",
            "Requirement already satisfied: openpyxl>=3.0.3 in /usr/local/lib/python3.8/dist-packages (from niapy==2.0.2->sklearn-nature-inspired-algorithms) (3.0.10)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
            "\u001b[K     |████████████████████████████████| 295 kB 64.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.5->sklearn-nature-inspired-algorithms) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.5->sklearn-nature-inspired-algorithms) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.5->sklearn-nature-inspired-algorithms) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.5->sklearn-nature-inspired-algorithms) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.5->sklearn-nature-inspired-algorithms) (1.4.4)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.5->sklearn-nature-inspired-algorithms) (0.11.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.3->niapy==2.0.2->sklearn-nature-inspired-algorithms) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.4->sklearn-nature-inspired-algorithms) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.5->sklearn-nature-inspired-algorithms) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->sklearn-nature-inspired-algorithms) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.2->sklearn-nature-inspired-algorithms) (1.2.0)\n",
            "Collecting numpy<2.0.0,>=1.22\n",
            "  Downloading numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.9 MB 641 kB/s \n",
            "\u001b[?25hInstalling collected packages: numpy, fonttools, contourpy, pandas, matplotlib, niapy, sklearn-nature-inspired-algorithms\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: niapy\n",
            "    Found existing installation: niapy 2.0.4\n",
            "    Uninstalling niapy-2.0.4:\n",
            "      Successfully uninstalled niapy-2.0.4\n",
            "Successfully installed contourpy-1.0.6 fonttools-4.38.0 matplotlib-3.6.2 niapy-2.0.2 numpy-1.22.4 pandas-1.5.2 sklearn-nature-inspired-algorithms-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install sklearn-nature-inspired-algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOUE4gTGFz9K",
        "outputId": "6241755f-38e5-40d8-96fa-318358717adc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.4.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n",
            "Installing collected packages: colorama, bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.4.1 colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "VWCENWUzFQS9"
      },
      "outputs": [],
      "source": [
        "SEED = 1412\n",
        "Test_Ratio = 0.2\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXe7CpxsePCh",
        "outputId": "61a8320c-cb3b-404e-b5ef-9c1a20793867"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/final result bayesian')"
      ],
      "metadata": {
        "id": "6j9ivESMeUS2"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def Make_Db():\n",
        "  X,y = make_classification(n_samples=10000,n_features=5,n_informative=2,n_classes=2,n_clusters_per_class=1,flip_y=float(f'0.{SEED}'),shuffle=False,random_state=SEED)\n",
        "  #95 -> 4.5%\n",
        "  #90 -> 14%\n",
        "  #89 -> 14.12%\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = Test_Ratio, random_state = SEED)\n",
        "\n",
        "  Train = pd.DataFrame(X_train)\n",
        "  Train['Answers'] = y_train\n",
        "  Test = pd.DataFrame(X_test)\n",
        "  Test['Answers'] = y_test\n",
        "\n",
        "  Train.to_csv('Train.csv')\n",
        "  Test.to_csv('Test.csv')\n"
      ],
      "metadata": {
        "id": "nkcqKuoze_xG"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Train.csv' not in os.listdir() or 'Test.csv' not in os.listdir(): \n",
        "  Make_Db()\n",
        "  if 'Final Result.json' in os.listdir():\n",
        "    os.remove('Final Result.json')\n"
      ],
      "metadata": {
        "id": "U9EhD0e0j0Oh"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train = pd.read_csv('Train.csv')\n",
        "Test = pd.read_csv('Test.csv')\n",
        "col_lst = list(Test.columns)\n",
        "col_lst.remove('Answers')\n",
        "col_lst = [i for i in col_lst if not i.startswith('Unnamed')]\n",
        "X_train = Train[col_lst]\n",
        "X_test = Test[col_lst]\n",
        "y_train = Train['Answers']\n",
        "y_test = Test['Answers']"
      ],
      "metadata": {
        "id": "sEYaYCfwWncq"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Test),len(Train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjwzmHJ9ei3T",
        "outputId": "bca4be9d-0811-465a-81c5-631cbe3eb966"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 8000)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "hQa-0Ofoe8yQ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np \n",
        "import niapy\n",
        "from sklearn_nature_inspired_algorithms.model_selection import NatureInspiredSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MyFinalResultDict = dict()\n",
        "\n",
        "try:\n",
        "  with open('Final Result.json','r') as dict_dump:\n",
        "      MyFinalResultDict = json.load(dict_dump)\n",
        "except:\n",
        "  pass \n",
        "\n",
        "def Save_Final_Dict():\n",
        "  with open('Final Result.json','w') as dict_dump:\n",
        "      json.dump(MyFinalResultDict,dict_dump)\n",
        "  print('Just dumped it!')"
      ],
      "metadata": {
        "id": "YgjbMWNlgDLh"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsGsiIt8e8yR"
      },
      "source": [
        "SCORING FUNCTIONS (6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbhs_5Bhe8yS"
      },
      "source": [
        "CUCKOO SEARCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "RPrU3DTMe8yS"
      },
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic import CuckooSearch\n",
        "\n",
        "CucKoo_pbounds = {'population_size':(10,100),'pa':(0.1,1.0) ,'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "Cuckoo_dict = dict()\n",
        "\n",
        "def Save_cuckoo_dict():\n",
        "    with open('Cuckoo_results.json','w') as dict_dump:\n",
        "        json.dump(Cuckoo_dict,dict_dump)\n",
        "    MyFinalResultDict['Cuckoo Top 10'] = sorted(Cuckoo_dict.items())[-10:]\n",
        "\n",
        "\n",
        "def Score_Cuckoo(population_size,pa,n_estimator,criterion,max_feature):\n",
        "    \n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "\n",
        "    combo_str = f'{population_size}_{pa}_{n_estimator}_{criterion}_{max_feature}'\n",
        "\n",
        "    if combo_str in Cuckoo_dict:\n",
        "        return Cuckoo_dict[combo_str]\n",
        "\n",
        "    Algo = CuckooSearch()\n",
        "    Algo.set_parameters(population_size=population_size,pa=pa,seed=SEED)\n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),\n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1\n",
        "    )\n",
        "    nia_mdl.fit(X_train,y_train)\n",
        "    val = nia_mdl.score(X_test,y_test)\n",
        "    Cuckoo_dict[combo_str] = val \n",
        "\n",
        "    return val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjwskMKUe8yT"
      },
      "source": [
        "CUCKOO SEARCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKpXd9zWe8yT"
      },
      "source": [
        "FIRE FLY "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "th9hn7Yge8yU"
      },
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic import FireflyAlgorithm\n",
        "\n",
        "FireFly_pbounds = {'population_size':(10,100),'alpha':(0.1,1.0),'beta0':(0.01,100),'gamma':(0.1,1.0),'theta':(0.1,1.0),'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "Firefly_dict = dict()\n",
        "\n",
        "def Save_firefly_dict():\n",
        "    with open('Firefly_results.json','w') as dict_dump:\n",
        "        json.dump(Firefly_dict,dict_dump)\n",
        "    MyFinalResultDict['FireFly Top 10'] = sorted(Firefly_dict.items())[-10:]\n",
        "\n",
        "def Score_Firefly(population_size,alpha,beta0,gamma,theta,n_estimator,criterion,max_feature):\n",
        "    \n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "\n",
        "    combo_str = f'{population_size}_{alpha}_{beta0}_{gamma}_{theta}_{n_estimator}_{criterion}_{max_feature}'\n",
        "\n",
        "    if combo_str in Firefly_dict:\n",
        "        return Firefly_dict[combo_str]\n",
        "\n",
        "    Algo = FireflyAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,alpha=alpha,beta0=beta0,gamma=gamma,theta=theta,seed=SEED)\n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1\n",
        "    )\n",
        "    nia_mdl.fit(X_train,y_train)\n",
        "    val = nia_mdl.score(X_test,y_test)\n",
        "    Firefly_dict[combo_str] = val \n",
        "\n",
        "    return val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr6i5YwNe8yU"
      },
      "source": [
        "FIRE FLY "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC4cSoSpe8yU"
      },
      "source": [
        "BAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "FHruFa4Ae8yV"
      },
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic import BatAlgorithm\n",
        "\n",
        "BAT_pbounds = {'population_size':(10,100),'loudness':(0.1,1.0),'pulse_rate':(0.1,1.0),'gamma':(0.1,1.0),'alpha':(0.1,1.0),'min_frequency':(0,10),'max_frequency':(10,100),'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "Bat_dict = dict()\n",
        "\n",
        "def Save_bat_dict():\n",
        "    with open('Bat_results.json','w') as dict_dump:\n",
        "        json.dump(Bat_dict,dict_dump)\n",
        "    MyFinalResultDict['Bat Top 10'] = sorted(Bat_dict.items())[-10:]\n",
        "\n",
        "\n",
        "def Score_Bat(population_size,loudness,pulse_rate,gamma,alpha,min_frequency,max_frequency,n_estimator,criterion,max_feature):\n",
        "    \n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "\n",
        "    combo_str = f'{population_size}_{loudness}_{pulse_rate}_{gamma}_{alpha}_{min_frequency}_{max_frequency}_{n_estimator}_{criterion}_{max_feature}'\n",
        "\n",
        "    if combo_str in Bat_dict:\n",
        "        return Bat_dict[combo_str]\n",
        "\n",
        "    Algo = BatAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,loudness=loudness,pulse_rate=pulse_rate,alpha=alpha,gamma=gamma,min_frequency=min_frequency,max_frequency=max_frequency,seed=SEED)\n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1\n",
        "    )\n",
        "    nia_mdl.fit(X_train,y_train)\n",
        "    val = nia_mdl.score(X_test,y_test)\n",
        "    Bat_dict[combo_str] = val \n",
        "\n",
        "    return val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1x7e8ioe8yW"
      },
      "source": [
        "BAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwQ5o3AJe8yW"
      },
      "source": [
        "SELF ADAPTIVE BAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "_NXOmcAYe8yX"
      },
      "outputs": [],
      "source": [
        "from niapy.algorithms.modified import AdaptiveBatAlgorithm\n",
        "\n",
        "SABA_pbounds = {'population_size':(10,100),'loudness':(0.1,1.0),'pulse_rate':(0.1,1.0),'epsilon':(0,0.1),'alpha':(0.1,1.0),'min_frequency':(0,10),'max_frequency':(10,100),'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "SBA_dict = dict()\n",
        "\n",
        "def Save_sba_dict():\n",
        "    with open('SBA_results.json','w') as dict_dump:\n",
        "        json.dump(SBA_dict,dict_dump)\n",
        "    MyFinalResultDict['SBA Top 10'] = sorted(SBA_dict.items())[-10:]\n",
        "\n",
        "def Score_SBA(population_size,loudness,pulse_rate,epsilon,alpha,min_frequency,max_frequency,n_estimator,criterion,max_feature):\n",
        "    \n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "\n",
        "    combo_str = f'{population_size}_{loudness}_{pulse_rate}_{epsilon}_{alpha}_{min_frequency}_{max_frequency}_{n_estimator}_{criterion}_{max_feature}'\n",
        "\n",
        "    if combo_str in SBA_dict:\n",
        "        return SBA_dict[combo_str]\n",
        "\n",
        "    Algo = AdaptiveBatAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,loudness=loudness,pulse_rate=pulse_rate,alpha=alpha,epsilon=epsilon,min_frequency=min_frequency,max_frequency=max_frequency,seed=SEED)\n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1\n",
        "    )\n",
        "    nia_mdl.fit(X_train,y_train)\n",
        "    val = nia_mdl.score(X_test,y_test)\n",
        "    SBA_dict[combo_str] = val \n",
        "\n",
        "    return val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9EvQl5Ce8yX"
      },
      "source": [
        "SELF ADAPTIVE BAT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdK4U0Z3e8yY"
      },
      "source": [
        "PARTICLE SWARM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "F2_0l7Kme8yY"
      },
      "outputs": [],
      "source": [
        "from niapy.algorithms.basic import ParticleSwarmAlgorithm\n",
        "\n",
        "PSA_pbounds = {'population_size':(10,100),'c1':(0,4),'c2':(0,4),'w':(0,1),'min_velocity':(-10,0),'max_velocity':(0,10),'repair':(0,5),'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "PSA_dict = dict()\n",
        "\n",
        "def Save_psa_dict():\n",
        "    with open('PSA_results.json','w') as dict_dump:\n",
        "        json.dump(PSA_dict,dict_dump)\n",
        "    MyFinalResultDict['PSA Top 10'] = sorted(PSA_dict.items())[-10:]\n",
        "\n",
        "def Score_PSA(population_size,c1,c2,w,min_velocity,max_velocity,repair,n_estimator,criterion,max_feature):\n",
        "\n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "    #limit, limit_inverse, wang, rand, reflect\n",
        "    repair_name = ''\n",
        "    if repair < 1.0:\n",
        "        repair = niapy.util.repair.limit\n",
        "        repair_name = 'limit'\n",
        "    elif repair < 2.0:\n",
        "        repair = niapy.util.repair.limit_inverse\n",
        "        repair_name = 'limit_inverse'\n",
        "    elif repair < 3.0:\n",
        "        repair = niapy.util.repair.wang\n",
        "        repair_name = 'wang'\n",
        "    elif repair < 4.0:\n",
        "        repair = niapy.util.repair.rand\n",
        "        repair_name = 'rand'\n",
        "    else:\n",
        "        repair = niapy.util.repair.reflect\n",
        "        repair_name = 'reflect'\n",
        "\n",
        "\n",
        "    combo_str = f'{population_size}_{c1}_{c2}_{w}_{min_velocity}_{max_velocity}_{repair_name}_{n_estimator}_{criterion}_{max_feature}'\n",
        "\n",
        "    if combo_str in PSA_dict:\n",
        "        return PSA_dict[combo_str]\n",
        "\n",
        "    Algo = ParticleSwarmAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,c1=c1,c2=c2,w=w,min_velocity=min_velocity,max_velocity=max_velocity,repair=repair,seed=SEED) \n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1,\n",
        "    )\n",
        "    nia_mdl.fit(X_train,y_train)\n",
        "    val = nia_mdl.score(X_test,y_test)\n",
        "    PSA_dict[combo_str] = val \n",
        "\n",
        "    return val\n",
        "Link = 'https://www.researchgate.net/profile/Mohamed_Mourad_Lafifi/post/Which-is-the-best-swarm-size-in-PSO/attachment/5b5b6f85b53d2f89289c14e1/AS%3A653084896288769%401532718981208/download/Good+Parameters+for+Particle+Swarm+Optimization.pdf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVoHknq7e8yY"
      },
      "source": [
        "PARTICLE SWARM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CamelAlgorithm"
      ],
      "metadata": {
        "id": "E8f_g9pPjBJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from niapy.algorithms.basic import CamelAlgorithm\n",
        "\n",
        "camel_bounds = {'population_size':(10,100), 'burden_factor':(0.1,1.0), 'death_rate':(0.1,1.0), 'visibility':(0.1,1.0),'supply_init':(1,1000),'endurance_init':(0,1000), 'min_temperature':(-100,0), 'max_temperature':(1,100),'n_estimator':(10,1000),'criterion':(0,1),'max_feature':(0,1)}\n",
        "\n",
        "camel_dict = dict()\n",
        "\n",
        "def Save_camel_dict():\n",
        "    with open('Camel_results.json','w') as dict_dump:\n",
        "        json.dump(camel_dict,dict_dump)\n",
        "    MyFinalResultDict['Camel Top 10'] = sorted(camel_dict.items())[-10:]\n",
        "\n",
        "def Score_camel(population_size,burden_factor,death_rate,visibility,supply_init,endurance_init,min_temperature,max_temperature,n_estimator,criterion,max_feature):\n",
        "\n",
        "    population_size = int(population_size)\n",
        "    n_estimator = int(n_estimator)\n",
        "    if criterion < 0.5:\n",
        "        criterion = 'gini'\n",
        "    else:\n",
        "        criterion = 'entropy'\n",
        "    if max_feature < 0.34:\n",
        "        max_feature = 'sqrt'\n",
        "    elif max_feature < 0.67:\n",
        "        max_feature = 'log2'\n",
        "    else:\n",
        "        max_feature = None\n",
        "\n",
        "    combo_str = f'{population_size}_{burden_factor}_{death_rate}_{visibility}_{supply_init}_{endurance_init}_{min_temperature}_{max_temperature}_{n_estimator}_{criterion}_{max_feature}'\n",
        "\n",
        "    if combo_str in camel_dict:\n",
        "        return camel_dict[combo_str]\n",
        "\n",
        "    Algo = CamelAlgorithm()\n",
        "    Algo.set_parameters(population_size=population_size,burden_factor=burden_factor,death_rate=death_rate,visibility=visibility,supply_init=supply_init,endurance_init=endurance_init,min_temperature=min_temperature,max_temperature=max_temperature,seed=SEED) \n",
        "\n",
        "    nia_mdl = NatureInspiredSearchCV(\n",
        "        estimator=RandomForestClassifier(n_estimators=n_estimator,criterion=criterion,max_features=max_feature),         \n",
        "        param_grid={},\n",
        "        algorithm=Algo,\n",
        "        runs=1,\n",
        "    )\n",
        "    nia_mdl.fit(X_train,y_train)\n",
        "    val = nia_mdl.score(X_test,y_test)\n",
        "    camel_dict[combo_str] = val \n",
        "\n",
        "    return val"
      ],
      "metadata": {
        "id": "C0T8P9H4jBW3"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CamelAlgorithm"
      ],
      "metadata": {
        "id": "KVnO6a5_jBkc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiG9DsyJe8yY"
      },
      "source": [
        "SCORING FUNCTIONS (6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Z1IZsle8yZ"
      },
      "source": [
        "FUNCTION LIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "5hKJv7nizJlS"
      },
      "outputs": [],
      "source": [
        "\n",
        "NIA_Val_Dict = {0:'Cuckoo Search',1:'Fire Fly',2:'Bat',3:'Self Adaptive Bat',4:'Particle Swarm', 5:'Camel Algorithm'}\n",
        "\n",
        "NIA_lst = [CucKoo_pbounds, FireFly_pbounds, BAT_pbounds, SABA_pbounds, PSA_pbounds, camel_bounds]\n",
        "\n",
        "Save_dict_fxn = [Save_cuckoo_dict, Save_firefly_dict, Save_bat_dict, Save_sba_dict, Save_psa_dict, Save_camel_dict]\n",
        "\n",
        "NIA_Score_fxn = [Score_Cuckoo, Score_Firefly, Score_Bat, Score_SBA, Score_PSA, Score_camel]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYISMKude8yZ"
      },
      "source": [
        "FUNCTION LIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQnCJhq-e8yZ"
      },
      "source": [
        "BASE CASE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "iJBq20nrzlX5"
      },
      "outputs": [],
      "source": [
        "if len(MyFinalResultDict) == 0:\n",
        "  clf = RandomForestClassifier()\n",
        "  clf.fit(X_train, y_train)\n",
        "  val = clf.score(X_test,y_test)\n",
        "  print(f'The default value is -> {val}')\n",
        "  MyFinalResultDict['Base Result'] = val\n",
        "  Save_Final_Dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zswUbhB_e8yZ"
      },
      "source": [
        "BASE CASE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Wq_S7p7fe8ya"
      },
      "outputs": [],
      "source": [
        "from bayes_opt import BayesianOptimization, UtilityFunction\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "CagnD0eWe8ya"
      },
      "outputs": [],
      "source": [
        "def Optimize_and_plot(bounds,score_fxn,Algo_name:str,Iters:int,Dict_save_fxn):\n",
        "  \n",
        "    print(f'Currently at {Algo_name}')\n",
        "\n",
        "    optimizer = BayesianOptimization(f = None, pbounds = bounds, verbose = 2, random_state = SEED)\n",
        "    utility = UtilityFunction(kind = \"ucb\", kappa = 1.96, xi = 0.01)\n",
        "\n",
        "    for i in range(Iters):\n",
        "        # Get optimizer to suggest a new parameter value to try.\n",
        "        next_point = optimizer.suggest(utility)  \n",
        "        # Evaluate the output of the black_box_function using the new parameter value.\n",
        "        target = score_fxn(**next_point)\n",
        "        try:\n",
        "            # Update the optimizer with the evaluation results. This needs to be in try-except\n",
        "            # to prevent repeat errors from occuring.\n",
        "            optimizer.register(params = next_point, target = target)\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    print(f'Best result: {optimizer.max[\"params\"]}; f(x) = {optimizer.max[\"target\"]}.')\n",
        "\n",
        "    Dict_save_fxn()\n",
        "    \n",
        "\n",
        "    plt.plot(range(1, 1+len(optimizer.space.target)), optimizer.space.target, \"-o\")\n",
        "    plt.grid(True)\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{Algo_name}_{Iters}_Iterations.svg',format='svg')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KJEEtHze8ya",
        "outputId": "f1f46ff2-ea7c-4eef-a552-cba46ff25efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently at Cuckoo Search\n",
            "Fitting at most 1.0 candidates\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(MyFinalResultDict)-1,len(NIA_lst)):\n",
        "    Optimize_and_plot(bounds=NIA_lst[i],score_fxn=NIA_Score_fxn[i],Algo_name=NIA_Val_Dict[i],Dict_save_fxn=Save_dict_fxn[i],Iters=100)\n",
        "    Save_Final_Dict()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br_NO9vMGbt9"
      },
      "source": [
        "function ClickConnect(){\n",
        "               \n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"#comments > span\").click() \n",
        "}\n",
        "setInterval(ClickConnect,5000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "bcac82fb26a6e7c950421e78519edb87e1a5e005e0aec2fc293e679965bb2493"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}